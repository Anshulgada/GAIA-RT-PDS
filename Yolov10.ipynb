{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# YOLOv10 Training and Inference Notebook\n",
        "\n",
        "This notebook contains steps to prepare, train, evaluate, and export a YOLOv10 object detection model for pothole detection. Sections are organized to make it easy to run step-by-step on Google Colab or a similar environment. Do not modify code cells unless you know what you are doing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment and Drive Mount\n",
        "\n",
        "Mount your Google Drive to access datasets, models, and outputs. If you are running locally, skip the drive mount and update paths accordingly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFAD5jtpHlQQ",
        "outputId": "453777e2-043e-4b89-8632-c91f1aed3747"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No LSB modules are available.\n",
            "Distributor ID:\tUbuntu\n",
            "Description:\tUbuntu 20.04.6 LTS\n",
            "Release:\t20.04\n",
            "Codename:\tfocal\n"
          ]
        }
      ],
      "source": [
        "!lsb_release -a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY6T3GpIN8oB",
        "outputId": "ebb8c015-8f4a-42b4-fb37-a40bf7525fba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiU8sSlDM1ej",
        "outputId": "138d1639-9b1f-4b11-8905-3d2e20e53c19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/PDS\n"
          ]
        }
      ],
      "source": [
        "!cd /content/drive/MyDrive/PDS/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6OmcLEEM3Dm",
        "outputId": "b43094b8-f071-46d3-a25c-67050a6111bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \u001b[0m\u001b[01;34mDatasets\u001b[0m/   data.yaml  \u001b[01;34m'Inference Images'\u001b[0m/   \u001b[01;34mModels\u001b[0m/   settings.yaml   \u001b[01;34mtrain\u001b[0m/   Yolov10.ipynb\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check the configuration of data.yaml file\n",
        "!cat /content/drive/MyDrive/PDS/data.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## System and GPU Checks\n",
        "\n",
        "Check the runtime environment and GPU availability. These steps help confirm that CUDA and a compatible GPU are present before training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUNGorgzQliV"
      },
      "outputs": [],
      "source": [
        "!pip install nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bS6Q0dXhJoWq"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU is detected:\n",
            "Fri May 24 14:18:58 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.161.08             Driver Version: 535.161.08   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA L4                      Off | 00000000:35:00.0 Off |                    0 |\n",
            "| N/A   35C    P8              16W /  72W |      0MiB / 23034MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "\n",
        "# Run nvidia-smi command to check GPU status\n",
        "result = subprocess.run([\"nvidia-smi\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(\"GPU is detected:\")\n",
        "    print(result.stdout.decode(\"utf-8\"))\n",
        "else:\n",
        "    print(\"GPU is not detected.\")\n",
        "    print(result.stderr.decode(\"utf-8\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Name: NVIDIA L4\n",
            "GPU Memory Total: 22699.875 MB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.cuda.current_device()\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(device)}\")\n",
        "    print(\n",
        "        f\"GPU Memory Total: {torch.cuda.get_device_properties(device).total_memory / (1024 ** 2):.2f} MB\"\n",
        "    )\n",
        "    print(\n",
        "        f\"GPU Memory Total: {torch.cuda.get_device_properties(device).total_memory / (1024 ** 3):.2f} GB\"\n",
        "    )\n",
        "else:\n",
        "    print(\"No GPU available.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Dependencies\n",
        "\n",
        "Install required Python packages such as `ultralytics` and `roboflow`. Run these before executing dataset download, training, or inference cells.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lztT5G8JRRQ"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics\n",
        "!pip install roboflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "455lKxQeRvPD"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Download and Preparation\n",
        "\n",
        "Download the dataset from Roboflow or provide your own dataset path. Ensure the `data.yaml` file paths are correct before training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXhuahMGJf3y"
      },
      "outputs": [],
      "source": [
        "# Download and Load Dataset (8315 Images for testing model training, final training with 50k images)\n",
        "# url: https://universe.roboflow.com/pothole-annotation-np4pr/pds-new/dataset/1\n",
        "\n",
        "from roboflow import Roboflow\n",
        "\n",
        "try:\n",
        "    rf = Roboflow(api_key=\"...\")  # Enter your API key here\n",
        "    project = rf.workspace(\"...\").project(\n",
        "        \"...\"\n",
        "    )  # Enter your workspace and project name here\n",
        "\n",
        "    version = project.version(1)\n",
        "    dataset = version.download(\"yolov10\")\n",
        "except Exception as e:\n",
        "    print(\"Error downloading dataset:\", e)\n",
        "\n",
        "# Uses old ultralytics version so manually upload dataset\n",
        "\n",
        "# If you have a dataset on device,\n",
        "# comment out the above lines\n",
        "# and upload your dataset manually"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training the YOLOv10 Model\n",
        "\n",
        "Train the model using the chosen YOLOv10 architecture. Adjust `model`, `data`, `epochs`, and `imgsz` as needed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqiaIyVeJhdJ",
        "outputId": "910ab50f-cec1-4218-ec5e-d027da70fa78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.2.38 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/drive/MyDrive/PDS/Models/yolov10m.pt, data=/content/drive/MyDrive/PDS/data.yaml, epochs=30, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 15.0MB/s]\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1     78720  ultralytics.nn.modules.block.SCDown          [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1    228672  ultralytics.nn.modules.block.SCDown          [384, 576, 3, 2]              \n",
            "  8                  -1  2   1689984  ultralytics.nn.modules.block.C2fCIB          [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1   1253088  ultralytics.nn.modules.block.PSA             [576, 576]                    \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 17                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  2    831744  ultralytics.nn.modules.block.C2fCIB          [576, 384, 2, True]           \n",
            " 20                  -1  1    152448  ultralytics.nn.modules.block.SCDown          [384, 384, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  2   1911168  ultralytics.nn.modules.block.C2fCIB          [960, 576, 2, True]           \n",
            " 23        [16, 19, 22]  1   2282134  ultralytics.nn.modules.head.v10Detect        [1, [192, 384, 576]]          \n",
            "YOLOv10m summary: 498 layers, 16485286 parameters, 16485270 gradients, 64.0 GFLOPs\n",
            "\n",
            "Transferred 787/799 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n",
            "100% 6.23M/6.23M [00:00<00:00, 72.9MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/PDS/Datasets/665 Images/train/labels... 1394 images, 0 backgrounds, 0 corrupt: 100% 1394/1394 [08:40<00:00,  2.68it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/PDS/Datasets/665 Images/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/PDS/Datasets/665 Images/valid/labels... 133 images, 0 backgrounds, 0 corrupt: 100% 133/133 [00:47<00:00,  2.79it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/PDS/Datasets/665 Images/valid/labels.cache\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 129 weight(decay=0.0), 142 weight(decay=0.0005), 141 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/30       9.5G      3.444      5.856      3.568         60        640:  99% 87/88 [01:06<00:00,  1.57it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "       1/30      9.57G      3.453      5.865      3.592          2        640: 100% 88/88 [01:07<00:00,  1.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:04<00:00,  1.04it/s]\n",
            "                   all        133        359    0.00592    0.00279   0.000746   0.000348\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/30      9.44G      3.686      4.392      3.646         14        640: 100% 88/88 [00:59<00:00,  1.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.17it/s]\n",
            "                   all        133        359      0.102      0.256     0.0562     0.0196\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/30      9.44G      3.642      4.217      3.645          5        640: 100% 88/88 [00:58<00:00,  1.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.20it/s]\n",
            "                   all        133        359      0.219      0.295      0.148     0.0601\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/30      9.42G      3.627       4.01      3.618         13        640: 100% 88/88 [01:00<00:00,  1.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.24it/s]\n",
            "                   all        133        359      0.411      0.443      0.358      0.171\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/30      9.48G      3.469      3.711      3.455          6        640: 100% 88/88 [00:58<00:00,  1.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.17it/s]\n",
            "                   all        133        359      0.404      0.396      0.366      0.183\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/30      9.45G      3.433      3.507      3.392         10        640: 100% 88/88 [00:58<00:00,  1.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  1.88it/s]\n",
            "                   all        133        359      0.548      0.451       0.41      0.207\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/30      9.45G      3.285      3.303      3.295         11        640: 100% 88/88 [00:58<00:00,  1.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:03<00:00,  1.35it/s]\n",
            "                   all        133        359      0.534      0.471      0.461       0.21\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/30      9.44G      3.291      3.365      3.325          8        640: 100% 88/88 [01:00<00:00,  1.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  1.94it/s]\n",
            "                   all        133        359      0.558      0.552      0.544      0.281\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/30      9.49G      3.194      3.124      3.253          5        640: 100% 88/88 [00:58<00:00,  1.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.16it/s]\n",
            "                   all        133        359      0.588      0.454      0.509      0.284\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/30      9.51G      3.136      2.953      3.176         12        640: 100% 88/88 [00:59<00:00,  1.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.02it/s]\n",
            "                   all        133        359      0.696      0.524      0.604      0.328\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/30      9.42G      3.112      2.882      3.182          6        640: 100% 88/88 [01:01<00:00,  1.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  1.90it/s]\n",
            "                   all        133        359      0.626      0.507       0.55      0.309\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/30      9.49G      3.106      2.809      3.121          3        640: 100% 88/88 [00:58<00:00,  1.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:03<00:00,  1.45it/s]\n",
            "                   all        133        359      0.679      0.624      0.681      0.386\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/30      9.44G      3.021      2.708      3.064         11        640: 100% 88/88 [00:58<00:00,  1.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  1.69it/s]\n",
            "                   all        133        359      0.545      0.457      0.465      0.252\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/30      9.48G          3      2.613      3.088         11        640: 100% 88/88 [00:57<00:00,  1.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.16it/s]\n",
            "                   all        133        359      0.718      0.604      0.662      0.372\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/30      9.42G      2.877      2.548      3.016         20        640: 100% 88/88 [01:00<00:00,  1.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.12it/s]\n",
            "                   all        133        359      0.767      0.585       0.69      0.402\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/30      9.46G      2.883      2.432       2.97          7        640: 100% 88/88 [00:58<00:00,  1.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.16it/s]\n",
            "                   all        133        359      0.759      0.563      0.655       0.38\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/30      9.42G      2.853      2.509       2.97         13        640: 100% 88/88 [00:58<00:00,  1.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  1.74it/s]\n",
            "                   all        133        359      0.691       0.61      0.657      0.386\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/30      9.41G       2.77      2.325      2.888          7        640: 100% 88/88 [00:58<00:00,  1.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:03<00:00,  1.47it/s]\n",
            "                   all        133        359      0.798      0.582      0.728      0.442\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/30      9.47G      2.743      2.241      2.849          9        640: 100% 88/88 [00:59<00:00,  1.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.18it/s]\n",
            "                   all        133        359      0.676      0.643      0.686      0.401\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/30      9.44G      2.684      2.176       2.86          9        640: 100% 88/88 [00:58<00:00,  1.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.15it/s]\n",
            "                   all        133        359      0.761      0.646      0.724      0.437\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/30      9.44G      2.564      1.842      2.787         14        640: 100% 88/88 [01:01<00:00,  1.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  1.83it/s]\n",
            "                   all        133        359      0.727      0.682      0.726      0.438\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/30       9.4G      2.522      1.754      2.758          5        640: 100% 88/88 [00:59<00:00,  1.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:03<00:00,  1.48it/s]\n",
            "                   all        133        359       0.71        0.6      0.687      0.406\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/30      9.45G      2.458      1.673      2.698          2        640: 100% 88/88 [00:57<00:00,  1.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.12it/s]\n",
            "                   all        133        359      0.767      0.633      0.747      0.469\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/30      9.45G      2.394      1.619      2.653          4        640: 100% 88/88 [00:58<00:00,  1.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.19it/s]\n",
            "                   all        133        359      0.814      0.609       0.74      0.446\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/30      9.42G      2.361       1.55      2.617          3        640: 100% 88/88 [00:57<00:00,  1.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  1.92it/s]\n",
            "                   all        133        359      0.803      0.613      0.741      0.457\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/30      9.41G      2.291      1.453       2.55          3        640: 100% 88/88 [00:59<00:00,  1.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.19it/s]\n",
            "                   all        133        359      0.837      0.657       0.76      0.482\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/30      9.41G       2.19      1.386      2.521          8        640: 100% 88/88 [00:57<00:00,  1.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.24it/s]\n",
            "                   all        133        359      0.761      0.663      0.749      0.485\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/30      9.43G      2.159      1.334      2.474          3        640: 100% 88/88 [00:57<00:00,  1.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.09it/s]\n",
            "                   all        133        359      0.774      0.657      0.762      0.476\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/30      9.46G      2.103      1.241      2.446          2        640: 100% 88/88 [00:59<00:00,  1.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:03<00:00,  1.57it/s]\n",
            "                   all        133        359      0.868       0.61      0.751      0.484\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/30      9.41G       2.07       1.22      2.412          5        640: 100% 88/88 [00:57<00:00,  1.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:03<00:00,  1.51it/s]\n",
            "                   all        133        359      0.845      0.621      0.756      0.488\n",
            "\n",
            "30 epochs completed in 0.537 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 33.5MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 33.5MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.38 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv10m summary (fused): 369 layers, 16451542 parameters, 0 gradients, 63.4 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:05<00:00,  1.07s/it]\n",
            "                   all        133        359      0.727      0.708      0.756      0.488\n",
            "Speed: 0.3ms preprocess, 13.4ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ],
      "source": [
        "# Train the model using YOLOv10m architecture as base model and the custom dataset\n",
        "# Change the model path if you want to use a different architecture (yolov10n, yolov10s, yolov10b, yolov10l, yolov10x)\n",
        "# Change the data path if your data.yaml file is in a different location\n",
        "\n",
        "!yolo task=detect \\\n",
        "     mode=train \\\n",
        "     model=/content/drive/MyDrive/PDS/Models/yolov10m.pt \\\n",
        "     data=/content/drive/MyDrive/PDS/data.yaml \\\n",
        "     epochs=30 \\\n",
        "     imgsz=640\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing and Inference\n",
        "\n",
        "Load the trained model and run inference on example images. Use `result.show()` to visualize predictions and `result.save()` to store outputs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uy1td5tOJjPB"
      },
      "outputs": [],
      "source": [
        "# Testing Results of Model\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\n",
        "    \"/content/drive/MyDrive/PDS/best.pt\"\n",
        ")  # Newly trained & finetuned YOLOv10m model\n",
        "\n",
        "\n",
        "# Run batched inference on a list of images\n",
        "results = model(\n",
        "    [\"/content/drive/MyDrive/PDS/Inference Images/p1.jpg\"]\n",
        ")  # return a list of Results objects\n",
        "\n",
        "# Process results list\n",
        "for result in results:\n",
        "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
        "    masks = result.masks  # Masks object for segmentation masks outputs\n",
        "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
        "    probs = result.probs  # Probs object for classification outputs\n",
        "\n",
        "    result.show()  # display to screen\n",
        "\n",
        "    result.save(\n",
        "        filename=\"/content/drive/MyDrive/PDS/Inference Images/p1-result.jpeg\"\n",
        "    )  # save to disk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Upload Trained Weights\n",
        "\n",
        "Optionally upload trained weights to Roboflow or another model hosting service for deployment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FEEfO38H5ne"
      },
      "outputs": [],
      "source": [
        "# Upload weights (Model to roboflow)\n",
        "\n",
        "from roboflow import Roboflow\n",
        "\n",
        "rf = Roboflow(api_key=\"...\")  # Enter your API key here\n",
        "project = rf.workspace(\"...\").project(\n",
        "    \"...\"\n",
        ")  # Enter your workspace and project name here\n",
        "project.version(1).deploy(\n",
        "    model_type=\"yolov10m\", model_path=\"/content/drive/MyDrive/PDS/train/\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export Model to EdgeTPU and ONNX\n",
        "\n",
        "Export the trained `best.pt` to formats suitable for edge deployment, such as EdgeTPU (tflite) and ONNX.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oi0sgaDfV-Yd"
      },
      "outputs": [],
      "source": [
        "# Export Model to EdgeTPU & ONNX\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\n",
        "    \"/content/drive/MyDrive/PDS/best.pt\"\n",
        ")  # Newly trained & finetuned YOLOv10m model\n",
        "\n",
        "model.export(\n",
        "    format=\"edgetpu\"\n",
        ")  # Export to EdgeTPU (tflite model for Google Coral Accelerator)\n",
        "\n",
        "model.export(format=\"onnx\")  # Export to ONNX format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Archive Trained Models\n",
        "\n",
        "Zip the training output folder to download or share the trained model artifacts easily.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "supwzGIWJjCZ"
      },
      "outputs": [],
      "source": [
        "# Zip the trained model folder for easy download\n",
        "!zip -r train.zip /content/runs/detect/train"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
